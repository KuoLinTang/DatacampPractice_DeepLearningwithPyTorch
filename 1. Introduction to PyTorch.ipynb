{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8ddc3f",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b064f",
   "metadata": {},
   "source": [
    "## Why PyTorch\n",
    "\n",
    "1. Easy to use\n",
    "2. Strong GPU support (fast)\n",
    "3. Many algorithms are already implemented\n",
    "4. Automatic differentiation\n",
    "5. Similar to Numpy (easy to learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd1fb4",
   "metadata": {},
   "source": [
    "## PyTorch compared to NumPy\n",
    "\n",
    "**一般 operations：**\n",
    "![](Image/Image1.jpg)\n",
    "\n",
    "---\n",
    "\n",
    "**矩陣乘法：**\n",
    "![](Image/Image2.jpg)\n",
    "\n",
    "---\n",
    "\n",
    "**Element-wise 乘法：**\n",
    "![](Image/Image3.jpg)\n",
    "\n",
    "---\n",
    "\n",
    "**產生 0 矩陣以及 1 矩陣**\n",
    "![](Image/Image4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16adce9f",
   "metadata": {},
   "source": [
    "### Torch Tensor and NumPy Array conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd9681",
   "metadata": {},
   "source": [
    "Torch Tensor 轉換成 NumPy Array： tensor.numpy() 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b09c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "\n",
    "# define a torch tensor\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# convert tensor into array and print\n",
    "print(t.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3518cb",
   "metadata": {},
   "source": [
    "NumPy Array 轉換成 Torch Tensor： torch.from_numpy(ARRAY) 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff2f2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "\n",
    "# define a numpy array\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(a)\n",
    "\n",
    "# convert array into tensor\n",
    "t_a = torch.from_numpy(a)\n",
    "print(t_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb4c4b",
   "metadata": {},
   "source": [
    "## PyTorch 重要的 operations 的函數\n",
    "\n",
    "![](Image/Image5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7a3d3",
   "metadata": {},
   "source": [
    "# Backpropagation by auto-differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d5f55",
   "metadata": {},
   "source": [
    "深度學習中最重要的數學就是計算微分，因為微分在幾何上代表了函數的斜率 (**Gradient**)，當斜率為 0 時就代表找到極值。因此，這裡要學習如何計算一個函數的偏微分。\n",
    "\n",
    "![](Image/Image6.jpg)\n",
    "\n",
    "上圖為一個函數的 computational graph。可知此函數 $f = q * z$，而 $q = x + y$。我們要計算 $f$ 在 $x$, $y$, $z$, $q$ 四個方向的微分值 (藍色的數字)。\n",
    "\n",
    "1. $f$ 的微分值必為 1，因為對自己微分必為 1\n",
    "2. $f$ 對 $q$ 的微分值為 -2。根據乘法定理，$$\\frac{df}{dq}\\ = \\frac{d}{dq}\\ (q*z) = \\frac{dq}{dq}\\ * z + q * \\frac{dz}{dq}\\ = z = -2 $$\n",
    "3. $f$ 對 $z$ 的微分值為 2。根據乘法定理，$$\\frac{df}{dz}\\ = \\frac{d}{dz}\\ (q*z) = \\frac{dq}{dz}\\ * z + q * \\frac{dz}{dz}\\ = q = 2 $$\n",
    "4. $f$ 對 $x$ 的微分值為 -2。根據乘法定理，$$\\frac{df}{dx}\\ = \\frac{d}{dx}\\ [(x+y)z] = \\frac{d(x+y)}{dx}\\ * z + (x+y) * \\frac{dz}{dx}\\ = z = -2 $$\n",
    "5.  $f$ 對 $y$ 的微分值為 -2。根據乘法定理，$$\\frac{df}{dy}\\ = \\frac{d}{dy}\\ [(x+y)z] = \\frac{d(x+y)}{dy}\\ * z + (x+y) * \\frac{dz}{dy}\\ = z = -2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333e3d1",
   "metadata": {},
   "source": [
    "## Implementation in PyTorch\n",
    "\n",
    "上面的微分都可以透過 PyTorch 的 backward() 函數來實踐。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6c135fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import torch\n",
    "\n",
    "# requires_grad 代表告知 PyTorch 我們要計算 gradients\n",
    "x = torch.tensor(-3., requires_grad = True)\n",
    "y = torch.tensor(5., requires_grad = True)\n",
    "z = torch.tensor(-2., requires_grad = True)\n",
    "\n",
    "# define the function\n",
    "q = x + y\n",
    "f = q * z\n",
    "\n",
    "# 計算 gradients\n",
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d2ef21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 在 x 向量方向的 gradient 為 tensor(-2.)\n",
      "f 在 y 向量方向的 gradient 為 tensor(-2.)\n",
      "f 在 z 向量方向的 gradient 為 tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# 印出結果\n",
    "print(\"f 在 x 向量方向的 gradient 為 {}\".format(str(x.grad)))\n",
    "print(\"f 在 y 向量方向的 gradient 為 {}\".format(str(y.grad)))\n",
    "print(\"f 在 z 向量方向的 gradient 為 {}\".format(str(z.grad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9169456",
   "metadata": {},
   "source": [
    "課堂練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8a5aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 2, requires_grad = True)\n",
    "y = torch.rand(2, 2, requires_grad = True)\n",
    "z = torch.rand(2, 2, requires_grad = True)\n",
    "\n",
    "# 矩陣乘法\n",
    "q = torch.matmul(x, y)\n",
    "\n",
    "# element-wise 乘法\n",
    "f = z * q\n",
    "\n",
    "# 求 f 所有 element 的平均\n",
    "mean_f = torch.mean(f)\n",
    "\n",
    "# 計算 gradients\n",
    "mean_f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9849b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 在 x 向量方向的 gradient 為 tensor([[0.0241, 0.1563],\n",
      "        [0.0136, 0.1125]])\n",
      "f 在 y 向量方向的 gradient 為 tensor([[0.0677, 0.2470],\n",
      "        [0.0487, 0.1611]])\n",
      "f 在 z 向量方向的 gradient 為 tensor([[0.2006, 0.1683],\n",
      "        [0.1339, 0.1047]])\n"
     ]
    }
   ],
   "source": [
    "# 印出結果\n",
    "print(\"f 在 x 向量方向的 gradient 為 {}\".format(str(x.grad)))\n",
    "print(\"f 在 y 向量方向的 gradient 為 {}\".format(str(y.grad)))\n",
    "print(\"f 在 z 向量方向的 gradient 為 {}\".format(str(z.grad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6be6b4",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "一般的 regression models 或 classification models 在相對完整的資料 (不需要 extract 複雜的 features) 表現可以很好。然而，當遇到某些狀況，例如： image recognition 或 language processing 時，由於我們要從一堆數字中找出影像或音訊的 features，而傳統的模型無法找出這些藏在數字中的 features。因此，我們才需要 neural networks 來找出潛在的 features。例如：Convolutional Neural Networks 可以利用 kernels 來找出特定的圖案 patterns。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c24df2",
   "metadata": {},
   "source": [
    "## Implementation in PyTorch (Linear Algebra approach)\n",
    "假設現在 input layer 有 10 個 nodes，第一個 hidden layer 有 20 個 nodes，第二個 hidden layer 有 20 個 nodes，而 output layer 有 4 個 nodes，且 layers 都屬於 Dense layer，則："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c05a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([317.2751, 299.5027, 231.7783, 256.8259])\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import torch\n",
    "\n",
    "# 隨機產生 input layer\n",
    "inputs_layer = torch.rand(10)\n",
    "\n",
    "# 第一個 hidden layer 與 input layer 之間的 weights\n",
    "weight1 = torch.rand(10, 20)\n",
    "\n",
    "# 計算第一個 hidden layer 中各個 nodes 的值\n",
    "hidden1 = torch.matmul(inputs_layer, weight1)\n",
    "\n",
    "# 第二個 hidden layer 與 第一個 hidden layer 之間的 weights\n",
    "weight2 = torch.rand(20, 20)\n",
    "\n",
    "# 計算第二個 hidden layer 中各個 nodes 的值\n",
    "hidden2 = torch.matmul(hidden1, weight2)\n",
    "\n",
    "# output layer 與 第二個 hidden layer 之間的 weights\n",
    "weight_out = torch.rand(20, 4)\n",
    "\n",
    "# 計算 4 個輸出\n",
    "outputs_layer = torch.matmul(hidden2, weight_out)\n",
    "\n",
    "# 印出結果\n",
    "print(outputs_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5007d94",
   "metadata": {},
   "source": [
    "上面的方法利用線性代數的矩陣乘法原理來計算 (forward propagation) 最後的輸出，是屬於較 low level 的方法，非常彈性，但建模過程麻煩且不直觀。 PyTorch 有提供較高階的方法 (跟 Tensorflow 的 keras.layers.Dense 類似)，可以較直覺的建立 neural networks 的模型。\n",
    "\n",
    "PyTorch 中高階的模型是一種物件導向的寫法 (Object-oriented)。寫法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be2e6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# 建立模型的類別\n",
    "class Net(nn.Module):\n",
    "    # constructor 中我們會透過 specify weights 來定義模型中各個 layers 的 nodes 的數量 \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # fully connected layers (dense layers) 在 PyTorch 中稱為 nn.Linear(目前layer的nodes數, 下一層layer的nodes數)\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.output = nn.Linear(20, 4)\n",
    "        \n",
    "    def forward(self, x):    # inputs 為 x\n",
    "        # apply all weights to the inputs\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ddc18",
   "metadata": {},
   "source": [
    "建立模型的物件，傳入 inputs，並且呼叫 forward method 來計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96ad23af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2081,  0.0588, -0.0061, -0.1764], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs_layer2 = torch.rand(10)\n",
    "\n",
    "# 建立模型物件\n",
    "net = Net()\n",
    "\n",
    "# 計算輸出結果\n",
    "outputs_layer2 = net.forward(inputs_layer2)\n",
    "\n",
    "# 印出結果\n",
    "print(outputs_layer2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
